---
title: "visualizations"
format: html
editor: visual
---

```{r}
# install.packages('tidytext')
library(tidyverse)
library(syuzhet)
library(tm)
library(ggplot2)
library(readtext)
library(tidytext)
```

```{r}
#transcript side is so that we split it per podcast episode
# grabs the file from podcasts to our computer
Pfiles <- list.files(path = "..\\data\\vox_podcasts", full.names = T, recursive = T)
Ptranscript <- readtext(Pfiles)

#cleans the transcript so that it only contains alphanumerics and creates a date column
Ptranscript_cleaned <- Ptranscript %>%
  mutate(text = str_remove_all(text, "[^[:alpha:][:space:]]"), date = str_extract(doc_id, "[0-9]*_[0-9]*_[0-9]*"))

#makes the date column a date variable
Ptranscript_cleaned$date <- as.Date(Ptranscript_cleaned$date,format = "%m_%d_%y")

#splits the cleaned transcript to individual words so that we can run an sentiment analysis on it
Ptranscript_split <- Ptranscript_cleaned %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words, by = "word")

##1562.74 words per podcast average

#Articles cleaning
VoxA_transcript <- readRDS("..\\data\\2024-2025_All_Vox_Articles.rds")
  

VoxA_cleaned <- VoxA_transcript %>%
  mutate(text = str_remove_all(text, "[^[:alpha:][:space:]]"), doc_id = title, date = datetime) %>%
  filter(text != "")
VoxA_cleaned$date <- format(VoxA_cleaned$date, "%Y-%m-%d")
VoxA_cleaned$date <- as.Date(VoxA_cleaned$date, format = "%Y-%m-%d")

VoxA_split <- VoxA_cleaned %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words, by = "word")

##680.40 words per article average
```

```{r}
Psentiment_transcript <- get_sentiment(Ptranscript_cleaned$text, method="syuzhet") # sentiment per document
Psentiment_whole <- mean(Psentiment_transcript)

Pnrc_data <- get_nrc_sentiment(Ptranscript$text) #nrc for text as a whole

PTranscriptDatebySentiment <- Ptranscript_cleaned %>%
  mutate(sentiment = Psentiment_transcript)

PTranscriptDatebySentimentfilter <- Ptranscript_cleaned %>%
  mutate(sentiment = Psentiment_transcript) %>%
  filter(date >= ymd("24-01-01"))


## Articles
Asentiment_transcript <- get_sentiment(VoxA_cleaned$text, method="syuzhet") # sentiment per document

Asentiment_whole <- mean(Asentiment_transcript)

Anrc_data <- get_nrc_sentiment(VoxA_transcript$text) #nrc for text as a whole

ATranscriptDatebySentiment <- VoxA_cleaned %>%
  mutate(sentiment = Asentiment_transcript)
```

```{r}
#Podcast
Pworstsentiment <- PTranscriptDatebySentiment %>%
  filter(sentiment == min(sentiment)) %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words, by = "word")

Pbestsentiment <- PTranscriptDatebySentiment %>%
  filter(sentiment == max(sentiment)) %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words, by = "word")

  Pbestsentiment_sen <- get_sentiment(Pbestsentiment$word, method="syuzhet")

  Pworstsentiment_sen <- get_sentiment(Pworstsentiment$word, method="syuzhet")
  
  
  #Articles
Aworstsentiment <- ATranscriptDatebySentiment %>%
  filter(sentiment == min(sentiment)) %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words, by = "word")

Abestsentiment <- ATranscriptDatebySentiment %>%
  filter(sentiment == max(sentiment)) %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words, by = "word")

  Abestsentiment_sen <- get_sentiment(Abestsentiment$word, method="syuzhet")

  Aworstsentiment_sen <- get_sentiment(Aworstsentiment$word, method="syuzhet")
```

```{r}
##Podcast
ggplot(PTranscriptDatebySentiment, aes(x = date, y = sentiment)) +
  geom_line() + 
  geom_point() +
  labs(title = "Sentiment over Time", x = "Date", y = "Sentiment Score") +
  geom_smooth()

ggplot(PTranscriptDatebySentimentfilter, aes(x = date, y = sentiment)) +
  geom_line() + 
  geom_point() +
  labs(title = "Sentiment over Time", x = "Date", y = "Sentiment Score") +
  geom_smooth()


plot(
  Pworstsentiment_sen,
  type="l",
  main="worst",
  xlab = "Narrative Time",
  ylab= "Emotional Valence"
  )

plot(
  Pbestsentiment_sen,
  type="l",
  main="best",
  xlab = "Narrative Time",
  ylab= "Emotional Valence"
  )
```

```{r}
##Articles
ggplot(ATranscriptDatebySentiment, aes(x = date, y = sentiment)) +
  geom_line() + 
  geom_point() +
  labs(title = "Sentiment over Time", x = "Date", y = "Sentiment Score") +
  geom_smooth()


plot(
  Aworstsentiment_sen,
  type="l",
  main="worst",
  xlab = "Narrative Time",
  ylab= "Emotional Valence"
  )

plot(
  Abestsentiment_sen,
  type="l",
  main="best",
  xlab = "Narrative Time",
  ylab= "Emotional Valence"
  )
```





