---
title: "Blog 1"
format: html
editor: visual
author: Aki Wada and Alec Chen
output:
  html_document:
    theme: journal
self-contained: true
---

```{r, echo = FALSE}
load("data/visualizations_worspace.RData")
```


## Sentiment Analysis on Vox Podcasts: Insights into the Voice of News

In the modern era it seems that people are moving farther and farther away from print media. With the advent of the 24 hour news cycle started at the turn of the century and the ever present diminishing attention span, People are now consuming their news in different media than their parents generation. Even as newspapers evolve more to be online in forms of online posts and websites, more people are more engaged in media that can be listened to. So as news changes the way it is dispersed how does that change the way news is received?

In our project we are specifically looking at the "sentiment" of podcast episodes and news articles. First we wanted to get a consistent type of content from both the articles and the podcast. So we decided that meant we used the same source for both, Vox. Vox has both a news podcast section called "Voxxed: Explained" and a standard print news section.

### Big Questions

Given the breadth and depth of Vox's catalog of articles and podcasts, we decided to focus on two main areas in the comparison between Vox podcasts and articles.

-   What is the overall sentiment across Vox's podcasts, and how does it vary by topic?

-   Does sentiment shift during specific episodes, perhaps reflecting the emotional arc of the conversation?

We conducted this analysis on all vox podcasts and vox articles up to December 16th 2024.

### Getting the Data

We scraped 1980 articles from 2024-2025 from the vox.com website using the `rvest` package. We filtered articles that were chronologies / timelines of major events that occurred those aren't exactly articles. We also removed articles that were aggregations of links to other articles but had little to no text.

We downloaded all the 256 podcast transcripts from the vox [google drive](https://drive.google.com/drive/u/0/folders/1XCO3CPKvMqIwJFqLGDMrIic2opQV0YWP). We removed all non-alphanumeric letters since they didn't provide any emotional connotation. 

### Word Frequency Analysis

We first analyzed the distribution of words in vox podcasts and vox articles. We took the top twenty most frequent words out of the vox podcasts and vox articles. We removed words that provided no emotional meaning like "and" and "the".

![](figures/vox_podcasts_top_words.png)

For vox podcasts, words like "like," "know," "think," and "really" suggest that the conversational and relatable tone of Vox podcasts remains a strong characteristic. Recurring words like "Trump" and "Noel" indicate important and recurring characters on the show. In this case, "Noel" and "Sean" are both the authors of the podcast so their names are frequent words where the word "Trump" indicates that the Vox podcast talks about Trump a significant amount of the time.

![](figures/vox_articles_top_words.png)

In vox articles, we see similar informal language like "like" and "also". The topics are similar with the word "Trump" ranking similarly highly among vox articles. This suggests both vox podcasts and articles have a slightly positive to neutral tone

We can visualize these word frequencies in a word cloud. Below is the word cloud for vox podcasts. The green word "people" and smaller in size purple word "right" indicate that Vox podcast is a human-centric podcast focused on correct decisions in terms of societal good. 

![Vox Podcast Word Cloud](figures/vox_podcasts_wordcloud.png)

The vox article word cloud shows many of the same words but notably, the word "know" is missing. Of note, many of the smaller words on the vox article word cloud indicate much more formal language. For example words like "government", state" and "law" in the vox articles can be constrasted with words like "things", "part" and "yeah" from the vox podcast. 

![Vox Article Word Cloud](figures/vox_articles_wordcloud.png)

Overall, this suggests that while both vox podcasts and articles have a generally informal and approachable tone, vox articles are more formal than vox podcasts.

However, word frequency cannot tell the full story since it lacks the temporal and sequential nature of podcasts and articles. These metrics are aggregated over all podcasts and articles so we cannot know exactly when an the tone shifts in a conversation in a podcast or an article. As such we performed a more rigorous analysis of the sentiment in vox articles and podcasts using the package Syuzhet.

### Sentiment Analysis

You might be asking what is sentiment analysis? how does it work? Well sentiment analysis is a technique used to determine the emotional tone behind a body of text.

In our analysis, we used a simple form a sentiment analysis that assigns every word with an emotional valence. Binary sentiment analysis will simply find if a word evokes a positive emotion or a negative emotion. There are more complex forms of sentiment analysis that take in multiple emotions. For example, the NRC Emotion Lexicon is a resource developed by the National Research Council of Canada that maps each individual word to an numerical value of emotion ie anger, fear, joy. We decided to use the Syuzhet sentiment analysis package since the process of building our own model would not have been as accurate or efficient as a pre-built model.

#### Pre-processing

We conducted the majority of our analysis in the year 2024-2025 since that was the year with the most consistent podcast upload schedule from vox. 

To do this, we split each podcast transcript into their individual words and pass each word through through a sentiment analysis pipeline. The pipeline takes each word from the transcript and assign it a sentiment value. For instance the word "love" has a sentiment value of 0.75, while the value of "murder" is -0.75. 

How do we get these sentiment values? Since language is so ambiguous, we have expert linguists label the numerical sentiment of each word without any context. These numerical values are aggregated into a larger dictionary or lexicon like the Syzuhet dictionary or the NRC Emotion Lexicon. We used both the Syzuhet dictionary and NRC Emotion Lexicon to perform our sentiment analysis. 

We first pre-processed the data for binary sentiment analysis.

```{r, echo = FALSE}
head(podcasts_sentiment_2024)
```

After cleaning and pre-processing, we found the sentiment scores for each podcast. There are some things to note. First, the news is moderately pretty positive, and podcast are even moreso! The sentiment for Articles are about a positive 8.25 on average on average while the average for podcasts seem are 15.12, double that of articles. This is odd since normally the news is associated with fear and negativity. 

If our model of language is correct and we can sum the sentiment of multiple words together, we can make a judgement that the podcasts are more positive than the articles.

```{r, echo = FALSE}
worst_sentiment_article %>%
  select(title, sentiment) %>%
  slice(1)

worst_sentiment_podcast %>%
  select(title, sentiment) %>%
  slice(1)
```

Digging deeper into the data, we decided to isolate the podcasts and articles with the best and worst sentiments. We found that the both articles and podcast were about wars in the middle east. Specifically, those wars were the Hamas-Israel conflict and the Sudanese civil war respectively. 

```{r, echo = FALSE}
best_sentiment_article %>%
  select(title, sentiment) %>%
  slice(1)

best_podcast_sentiment %>%
  select(title, sentiment) %>%
  slice(1)
```



By contrast the best article and podcast sentiment were on completely different topics. The best sentiment article was about having panic attacks about joy whereas the best sentiment podcast was about bringing back the SAT.

#### Visualization

**The year 2024**

The sentiment analysis of articles and podcasts over the year 2024 reveals similar trends and behaviors across the two media formats. 

For articles, the sentiment scores exhibit significant fluctuations throughout the year, with a mix of both highly positive and negative values. Despite this variability, a slight upward linear trend suggests a gradual increase in positivity over time. The data is densely clustered around the neutral score (0), indicating relative stability in sentiment despite frequent spikes and dips.

```{r,echo = FALSE, error = FALSE}
articles_2024_viz
```

Podcasts have simiarly significant fluctuations throughout the year. However, the general trend line seems to have a minor increase in positive sentiment, followed by a gradual decline toward the end of 2024. Podcasts seem to exhibit sharper sentiment scores in the greater than 40 in the negative and positive direction indicating people may use stronger words in conversation compared to text.

```{r, echo = FALSE, error = FALSE}
podcast_2024_viz
```

```{r}
article_worst
article_best
```




```{r}
##podcast
pemotions <- prop.table(Pnrc_data[, 1:8]) %>%
  colSums() %>%
  data.frame(Emotion = names(.), Percentage = .)

Aemotions <- prop.table(Anrc_data[, 1:8]) %>%
  colSums() %>%
  data.frame(Emotion = names(.), Percentage = .)

emotions <- pemotions %>%
  inner_join(Aemotions, by = "Emotion" ) %>%
  mutate("Podcast Percentage" = Percentage.x, "Article Percentage" = Percentage.y) %>%
  select(Emotion,"Podcast Percentage", "Article Percentage") %>%
  pivot_longer(cols = c("Article Percentage", "Podcast Percentage"),
               names_to = "Media", 
               values_to = "Percentage")

# Plot the side-by-side barplot
ggplot(emotions, aes(x = Emotion, y = Percentage, fill = Media)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Article NRC vs Podcast NRC",
       x = "Emotion", y = "Percentage of Sentiment", fill = "Media") +
  theme_minimal() +
  scale_fill_manual(values = c("Article Percentage" = "steelblue", "Podcast Percentage" = "darkorange"))
```

###NRC Emotional Valence

If we were to look at the specific emotional content of the words we find that both the articles and the podcast are very similar, almost exactly the same in percentage. First and foremost we can see that Vox prioritizes trust in their news coverage more than anything else. Which I would say is a good sign, as I would rather have that than fear mongering news stories. Although we can still see fear still has a relatively high percentage of the data, I think a good amount of fear is probably necessary in the news industry to stay alive (which comprimises the validity of the story, but I digress).

###Problems/Issues with our data

But as always there is some problem with our research. For one, we really only looked at one news site. It is very possible that Vox might be an exception and the data might not be applicable outside of Vox. for instance if we were to find some Media that has a speciality demographic, such as Shark News, or has a strong political lean, like Fox news, we might get completely different data.

Work Cited:

https://cran.r-project.org/web/packages/syuzhet/vignettes/syuzhet-vignette.html

https://stackoverflow.com/

sessionInfo()
